---
layout: post
title:  "movie"
date:   2020-05-03 08:25
categories: jekyll
permalink: /archivers/movie
---
# 파이썬 웹 크롤링 기초 (내이버 영화 댓글)
**목차** 

1.  **BeautifulSoup 시작하기**
2.  **태그(Tag) 탐색하기**
3.  **웹사이트 구조 분석하기 (개발자 도구)**
4.  **`Select`을 통해 원하는 부분 가져오기**
5.  **CSS 선택자를 통해 원하는 부분 가져오기**
6.  **텍스트만 읽어오기**

## 들어가기에 앞서 ###
일단 웹 사이트라는 걸 이해해야 한다. 기본적으로 웹사이트는 문서다. HTML이라는 형식으로 쓰여진 문서.

그래서 우리는 HTML 문서에 담긴 내용을 가져 오도록  **request**(요청) 해야 한다. 파이썬에는 애초에  `requests`라는 라이브러리로 편리하게 사용이 가능하다. (만약 설치가 안 되어 있다면 pip를 통해 설치하고 사용하자.)

이제 아래와 같이  `requests.get()`안에 url을 넣어서 사용할 수 있다. 예를 들어  [내이버 영화 댓글]([https://movie.naver.com/movie/sdb/rank/rmovie.nhn](https://movie.naver.com/movie/sdb/rank/rmovie.nhn))을 가져오고 싶다면 이렇게.
~~~phthon
import requests

webpage = requests.get("https://movie.naver.com/movie/sdb/rank/rmovie.nhn")

print(webpage.text)
~~~
코드를 실행하면 당근마켓 홈 화면의 HTML 문서 전체를 긁어서 출력해준다.

물론 HTML 문서를 제대로 읽으려면 문법을 이해하고 있어야 하겠지만, 너무 깊이 들어가진 말자. 어차피 여기서 필요한 부분만 뽑아내는 방법을 익히면 되는데, 여기서부터가 본격적인 크롤링이다.

## 1. BeautifulSoup 시작하기 ###

요청한 HTML을 프린트 해보면 매우 길고 지저분하다. 그래서 결국 라이브러리의 힘을 빌려야 한다. HTML 문서를 탐색해서 원하는 부분만 쉽게 뽑아낼 수 있는 파이썬 라이브러리  **BeautifulSoup**를 사용해보자.

아래와 같이 코드를 추가해봤다.
~~~py
import requests  
from bs4 import BeautifulSoup  
  
webpage = requests.get("https://movie.naver.com/movie/sdb/rank/rmovie.nhn")  
  
soup = BeautifulSoup(webpage.content, "html.parser")  
  
print(soup)
~~~
일단  `from bs4 import BeautifulSoup`로 라이브러리를 불러올 수 있다.

그리고 웹페이지를 요청한 뒤, 여기서 받아낸 문서를  `.content`로 지정한 후  `BeautifulSoup`를 통해 soup라는 객체로 저장하면 된다.

여기서 뒤에  `"html.parser"`라고 덧붙였다. 이외에도  `"lxml"`, `"html5lib"`  등의 옵션을 사용할 수 있으며 각각의 장단점이 있는데, 어쨌든 자세한 내용은 생략하고 (사실 나도 잘 모르니까) 그냥 일단 html로 하자.


## 2. 태그(Tag) 탐색하기 ###
 HTML 문서를 잘 보면 < > 기호를 활용해서 다양한 태그를 사용한다. HTML 문법까지 설명하면 너무 깊어지니… 넘어가자.

어쨌든 p 태그만 찾아서 출력해보자. 이렇게 하면 첫번째 p 태그를 찾아 준다.
~~~phthon
print(soup.p)
~~~

~~~html
 <p class="r_date">2020.05.08 
	 <a href="rmovie.nhn?sel=cnt&amp;tg=0&amp;date=20200507">
		 <img alt="prev" height="13" src="https://ssl.pstatic.net/imgmovie/2007/img/common/btn_prev.gif" style="margin-right:1px;" width="13"/>
	 </a>
 </p>

 ~~~
만약 태그 속성들은 빼고 그 안에 있는 텍스트만 깔끔하게 가져오고 싶다면 이렇게 써주면 된다 .

~~~phthon
print(soup.p.string)
~~~
None
이제 h1 태그도 한 번 출력해보자.

~~~phthon
print(soup.h1)
~~~



~~~html
<h1 class="svc_name">
	<a class="ci_logo" href="http://www.naver.com/" id="lnb_gonaver" onclick="clickcr(this, 'LNB.naver', '', '', event);" title="naver로 바로가기">
		<img alt="NAVER" height="13" 
src="https://ssl.pstatic.net/static/movie/2013/07/logo_ci.png" width="62"/>
	</a>
	<a class="svc_logo" href="/" onclick="clickcr(this, 'LNB.movie', '', '', event);" title="영화서비스홈으로 바로가기">
		<img alt="영화" height="19" src="https://ssl.pstatic.net/static/movie/2012/06/logo_svc.png" width="34"/>
	</a>
</h1>

~~~

그리고 태그는 보통 트리구조로 위계가 있기 때문에 하위 항목을 모두 뽑아오고 싶다면 `.children`을 사용하면 된다. 예를 들어 ul 태그 안에 리스트가 있다면 이렇게.
~~~phthon
for child in soup.ul.children:

print(child)
~~~

~~~html
<a class="ci_logo" href="http://www.naver.com/" id="lnb_gonaver" onclick="clickcr(this, 'LNB.naver', '', '', event);" title="naver로 바로가기">
	<img alt="NAVER" height="13" src="https://ssl.pstatic.net/static/movie/2013/07/logo_ci.png" width="62"/>
</a>


<a class="svc_logo" href="/" onclick="clickcr(this, 'LNB.movie', '', '', event);" title="영화서비스홈으로 바로가기">
	<img alt="영화" height="19" src="https://ssl.pstatic.net/static/movie/2012/06/logo_svc.png" width="34"/>
</a>

~~~
당연히 지정된 태그의 상위 항목을 가져올 수도 있다. 이건  `.parents`를 사용한다. 이건 ul 상위에 있는 body 태그를 출력한 후, 전체 html 까지 추가로 출력한다. 계속 상위로 타고 올라가는 거라 생각하면 된다
~~~ phthon
for parent in soup.ul.parents:

print(parent)
~~~
이번엔 div 태그 하위에 있는 요소들을 하나씩 출력하려면 이렇게 하면 된다.


~~~phthon
for d in soup.div.children:

print(d)
~~~

##  3. 웹사이트 구조 분석하기 (개발자 도구) ###

위와 같이 태그만으로 텍스트를 뽑아서 웹사이트 구조를 확인하는 건 너무 피곤한 일이다. 그래서 그걸 간편하게 도와줄 개발자 도구를 사용하는 게 좋다. 거의 모든 웹 브라우저는 개발자 도구를 사용할 수 있도록 되어 있다.

크롬에서는 그냥  **F12** 키를 누르면 바로 창이 뜬다. 내가 마우스를 어디에 갖다대는지에 따라 HTML 문서에서 해당하는 부분을 보여준다. 그러니 우리는 이걸 통해 웹사이트에 포함된 태그들을 확인하면 된다.
